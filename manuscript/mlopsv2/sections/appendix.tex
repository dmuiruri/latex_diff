
\subsection{Case A}
% Structure: ML solution/use case, data (type and collection), ML model development(Algorithm) and deployment(), team size
The ML solution presented by Case A is a computer vision (CV) project specifically an object detection solution where objects of interest are detected dynamically from a camera system mounted on a vehicle. Case A trains the model on video data which is collected via the cameras and sent to a cloud storage where it is pre-processed. Case A trains the object detection model in the cloud and deploys it back to the camera systems for inference purposes. Inference data is streamed from the cameras to the cloud to support other business functions.

\subsection{Case B}
% Makes use of both an OCR solution and a Chargrid-net based solution [Interview 6, 17:29] The system contains two main models (1) makes use of machine readable PDFs (Chargrid) (2) makes use of none-machine  readable image data (OCR).
Case B implements a document understanding solution based on the chargrid model where it is used to extract data from specified fields in digital documents. The system is aimed towards replacing an otherwise manual document handling process. Input data to the system are digital documents in Portable Document Format (PDF). These files are sent in by case B's clients and are uploaded to the company's private cloud for storage and pre-processing. Case B receives about 10 million of these digital documents on a monthly basis. The OCR model is trained in the case B's private infrastructure and the model is deployed in their private cloud for inference. Case B uses inferred predictions as input for other internal systems.

\subsection{Case C}
Case C also presented an optical character recognition (OCR) ML solution used to extract data from specified fields of a form in digital documents. The ML solution is also designed to automate an otherwise manual business process. Unlike case B, the input data for this system is images of documents which are often taken with mobile phone cameras. case C receives about 10 million images in a year and this image data is stored in the case C's private infrastructure. The model is trained and deployed in case C's private infrastructure. This system supports case C in generating data for their internal systems and processes.

\subsection{Case D}
Case D develops a Automatic Speech Recognition (ASR) ML solution designed for transcription of audio recording into text data. Audio data is primarily streamed in two ways: (1) Using a mobile application which sends the audio data to case D's servers in the cloud  or (2) using a desktop microphone connected to a web client which also uploads the data to a cloud server. On average, Case D receives about 300 hours worth of recordings per month for transcription. The ASR model is trained in a cloud environment and deployed in the cloud where clients access it as a SaaS\footnote{Software as a Service} product.

\subsection{Case E}
Case E also develops an ASR ML solution designed to provide a speech API\footnote{Application Programming Interface} for voice/speech based user interfaces. The solution is targeted at web and mobile developers who would want to enable voice as a feature that end users can use to interact with an application. The ML model is trained largely on publicly available voice datasets, typically from academic research groups. Case E has designed a markdown language that allows third party developers to adapt the ASR model to their application. Case E trains and deploys the ASR model in the cloud. 

\subsection{Case F}
Case F presented an ML pipeline automation (MLOps) product and a computer vision solution which was built using the pipeline automation product.The computer vision solution implements an object detection solution for predictive maintenance of power lines infrastructure.
The MLOps platform is YAML\footnote{https://yaml.org/} based where  pipeline steps such as data extraction, model training, evaluation and deployment stages are declaratively configured. The platform's inbuilt features support reproducibility, early stopping of long training cycles, task queues for parameter optimization among others. The platform further supports multiple cloud providers which means Case F's customer's can freely select their choice of cloud providers to build ML pipelines.


\subsection{Case G}
Case G presented a platform which includes tools and processes specifically designed for internal purposes to support a team that develops high frequency trading algorithms and models. The platform supports both ML models as well as rule based models. Typically, analysts and data scientists make use of time series of pricing data and other external data such as weather to develop their models. Data scientists use the system by implementing a "train" and "predict" API exposed by the platform. The platform also defines a standardised data serialization format (NetCDF \footnote{https://www.unidata.ucar.edu/software/netcdf/}) which ensures uniformity of input data and predictions. The platform is developed by a team known as the "platform team" which has a head count of 8-9 people. At the time we conducted the interviews, deployment related functions were not yet supported within the platform, instead such tasks required intervention of people from the platform team to ensure models are correctly deployed to production. 

\subsection{Case H}
Case H presented an analytics platform built on top of a data lake mainly designed to generate business and regulatory compliance reports. Case H operates in a highly regulated business sector which means data collected from end users follows strict storage and processing guidelines as stipulated in GDPR\footnote{General Data Protection Regulation} guidelines. In addition to business reporting, Case H's analytics platform is used  by teams that perform risk modeling which forms the ML part of the solutions developed in case H. The risk assessment models are used internally to support decision making, therefore case H does not view ML solutions as products but as tools used to support other core business processes. Data in the analytics platform is mainly comprised of data collected from other business systems within the enterprise of case H. The models are trained cloud and deployed in the public cloud although only used for internal purposes.

\subsection{Case I}
The ML solution in Case I relates to analytics used to mainly support predictive maintenance in an IoT setting. Generally, Case I implements a wide range of analytics, ranging from simple models of identifying sequence of fault events to complex models of detecting entrapment. Through the analytics ML use case, Case I can provide additional information to maintenance technicians working in the field about the current state and future failures of equipment ($\approx$ 1 million). Data is collected in two broad classes: (1) automatically from sensors of a massive IoT system and (2) manually by field technicians ($\approx$ 30,000 persons), who input operations while at the field using a mobile application in different regions across the globe. However, the specific data collection procedure in the two classes may vary depending on regional regulations and business operations. The collection and management of the IoT data as well as its storage in a centralized cloud environment is done by another team, and the team implementing the analytics in Case I has about 20-25 data scientists and engineers. 

\subsection{Case J}
Similar to Case I, the ML solution in Case J focused on predictive maintenance in an IoT setting, specifically in a paper manufacturing process. For example, a predictive model to detect problems in a subsystem used for mixing chemicals. Case J has a dedicated unit that helps the organization to collect, store and utilize data across different business units. IoT data is collected primarily from factory machine logs, but also operators who keep operational diaries for maintenance tasks. Azure IoT edge is used to make connection to the factory and collect machine log data that is then stored in databases. 


\subsection{Case K}
In Case K, the ML capabilities were implemented in a software system used in managing building facilities. Data is collected from devices or sensors in buildings (($\approx$ 20,000), such as energy and water meters as well from manual user inputs in of fault reports and external sources e.g., weather data. The data is used to develop ML models for detecting different anomalies in buildings, such as of energy/heating consumption that are useful to facilitate automation of tasks and analytics for Case K consultants and ultimately also to the customers. Two data scientists are actively working on ML model experiments and work collaboratively with about three software developers.


\subsection{Case L}
From the pharmaceutical industry, in Case L the focus in this study was on the use of ML for the purpose of data analysis, exploration of safety toxicology and feature selection from genome data in pre-clinical stages of clinical drug discovery research. The data that is used (e.g.,toxicology data) is collected from Case L's laboratory equipment as well as externally from publicly available data. The collected data is typically large ($\approx$ 60TB of data or more) depending on the disease and is often stored in Azure cloud. 


\subsection{Case M}
In Case M, the interviewees presented a natural language processing (NLP) solution for classification of transcribed verbal reports and an OCR system for document classification in a setting where different kinds of documents are received and automatically organized based on their type. As a consulting organisation, the NLP solution was for a client in healthcare and sought to identify potential work-related disabilities using a provided labelled dataset consisting of about 20,000 text records written by world health doctors. The OCR system was for a government agency and the interviewee was mostly involved in the maintenance of the system, including the implementation of model updates. For the latter, the work was mostly carried out at the client's site.


\subsection{Case N}
As a financial organisation, Case N has various ML use cases, however, in this study the focus was on ML models used to facilitate customer profiling API service as well as digital assistance in customer service, specifically chatbots. The chatbots are based on Finnish language and data is primarily collected from existing customer chats and dialogues with human clerks. For the customer profiling API service, data scientists data copied from enterprise data warehouse, which sources the data from various different systems. Integration of team's data lake to the enterprise warehouse ensure a collection of a portion of the whole data while also adhering to data privacy as well as its continuous governance and monitoring. In Case N, our interviewee was from a team consisting of more than 30 data scientists, who provide data science expertise and resources to the other business units. The data scientists are also part of a large data science community of Case N aiming to share, amongst others, best practices, tools and approaches to common problems.


\subsection{Case O}
The two interviewees from Case O shared experiences from creating a data lake for supporting ML operations and automation of the ML pipelines (MLOps). As a consultancy organization, one ML use case of reference tackled the problem of anomaly detection in bio-signals for a client that offering medical devices and their related systems and services globally. For this use case, data was primarily collected from selected patients that were being monitored as they used the devices. The data from the devices was offloaded in batches into a cloud environment.  


\subsection{Case P}
As a media company, Case P employs ML capabilities to develop recommendation and Ad classification systems for its Finnish online service, which integrates different services. Additionally, Case P creates different analytical reports and implements several use cases in digital advertisement, for example predicting user profiles, for its B2B clients. Data is collected from Case P's systems with the help of several different third party data collection partners that provide data via subscription based tools. These are used to gather, amongst others, user geolocation data, user actions or page views as well as impressions and Ad clicks on the online services. Data mostly collected by the third party partners is delivered in daily batches in the order of gigabytes and some times larger data damps (terabytes) covering monthly data are also received. However, Case P also has a few real-time data flows. 

%Project 16 is a Recommendation system designed to be integrated in web based media platforms. The system is used to create targeted online marketing and online campaigns.

%Projects 1-3 presented computer vision related projects. Project 1 is based on object detection where objects are detected from a camera mounted on a vehicle. Projects 2 and 3 focused on optical character recognition (OCR) used to extract data from fields of a form in digital documents. Interviews for project 3 hosted four interviewees with varying roles and work on different parts of the ML pipeline.

%Projects 4 and 5 are speech recognition systems with different application contexts. Project 4 is part of a speech-to-text product used in transcription of speech in real-time. Project 5 presents a speech recognition system used to develop a speech based user interface available to developers as an API.

%Projects 6 and 7 are based on machine learning operations. Project 6 presented a tool/product developed to automate machine learning operations by declaring an ML pipeline configuration through a YAML file. Project 7 other other hand presented as a platform that includes tools and processes specifically designed for internal purposes to support model production by data scientists.

%Projects 8-11 are analytics focused platforms with machine learning features. Project 8 presented an analytics platform with risk assessment features, risk in this case referes to a financial assessment of a consumer's risk profile. Project 9 and 10 presented analytics systems used to mainly support predictive maintenance in an IoT setting. Data collected from IoT sensors is used for analytics and modeled for predictive maintenance purposes. Project 11 also presented an analytics project which is also used in anomaly detection to determine anomalous readings from various third party meter devices.

%Project 12 is an environment used to perform exploratory data analysis. In this setting, the main focus for the team is to perform multiple data exploration tasks where the resulting analysis are the main objects of interest. The results are communicated and stored for further reference.

%Project 13 are two systems presented by two interviewees. One system is an NLP solution used for classification of transcribed verbal reports while the second system is an OCR system used for document classification in a setting where different kinds of documents are received and automatically organized based on their type. The interviewee was not involved in creating the OCR system but is involved in the maintenance of the system.

%Project 14 is an NLP project where the models are used to develop customer service chatbots. The chatbot system is based on the Finnish language.

%Project 15 hosted two interviewees where they co-presented experiences from creating a data lake for supporting machine learning operations and automation of the machine learning pipelines (MLOps).

%Project 16 is a Recommendation system designed to be integrated in web based media platforms. The system is used to create targeted online marketing and online campaigns.
