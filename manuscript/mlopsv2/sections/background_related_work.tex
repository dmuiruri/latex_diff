%This section presents empirical studies on development, deployment, and maintenance of ML-enabled systems. The focus is on works that describe the characteristics of industrial ML workflows and pipelines for ML systems.
%\red{should we add a section intro here? In other sections there is something, but here not?}

\subsection{Software engineering for machine learning}
Adaptation of well-established software engineering (SE) methods and approaches in ML systems have been reported to be crucial \cite{Amershi2019}. This perspective emphasizes important aspects of ML model development and operations in production, such as data management and serving infrastructure \cite{Sculley2015}. Earlier studies observed that companies with fewer years of experience in deploying to production ML components adopt less of the identified SE best practices in ML \cite{Serban2020Practices}. In addition, companies are also reported to face different SE challenges at different evolution stages of deploying ML components in software-intensive systems (experimentation \& prototyping, non-critical deployment, critical deployment, cascading deployment, and autonomous ML components) \cite{Lwakatare2019}.
%A taxonomy is proposed and used to map the SE challenges at each evolution stage (experimentation & prototyping, non-critical deployment, critical deployment, cascading deployment, and autonomous ML components). }

%Best SE practices in ML have been identified and their adoption in the industry surveyed %\st{in}
%\cite{Serban2020Practices}. 

The identified best SE practices in ML include those pertaining to data (e.g., employing sanity checks for all external data sources), training (e.g., use versioning for data, model, configurations and training scripts), coding (e.g., using continuous integration, deployment (e.g., enabling shadow deployment), team (e.g., collaborating with multidisciplinary team members), and governance (enforcing fairness and privacy) \cite{Serban2020Practices}. According to the authors \cite{Serban2020Practices}, the least adopted practices -- related to feature management, writing tests, shadow deployment and automated hyper-parameter optimization -- require effort, knowledge and tool support. 

%This interview study provides some validation and in-depth interpretation to the survey findings related to the adoption of \textcolor{green}{these} practices \cite{Serban2020Practices}.  

\subsection{ML workflow and pipelines}

ML workflows describe different tasks which are performed in order to develop, deploy and operate ML models in production \cite{Amershi2019}. ML pipelines are used to express complex input/output relationship between 
different tasks/operators of an automated ML workflow \cite{Doris2021MLPipelines}. Generally, ML pipelines plug together several tools to automate ML workflows \cite{Hummer2019IBM}.

A typical ML workflow life-cycle includes model requirements, data collection, data cleaning, data labelling, feature engineering, model training, model evaluation, model deployment and model monitoring \cite{Amershi2019}. Studies show that end-to-end automation of ML workflows improves both the development time and rate of deploying ML models \cite{Hummer2019IBM,Doris2021MLPipelines}. Furthermore, this allows organizations to automate orchestration of workflows steps, track and reproduce the outputs of a ML workflow, and reuse common steps of the workflow across multiple ML systems \cite{Baylor2017, Hummer2019IBM}. %In addition to ML workflow components, MLOps tools provide utilities to manage pipeline execution and schedule training jobs.

Few studies report in detail the characteristics of ML pipelines in terms of their components, and architectures \cite{Hummer2019IBM,Doris2021MLPipelines}. Different from our qualitative analysis, Xin et al \cite{Doris2021MLPipelines} quantitatively analysed over 3000 ML pipelines at Google and presented their high-level characteristic in terms of pipeline lifespan, complexity, and resource consumption. For the complexity of ML pipelines, the authors analyzed typical input data shape, feature transformation and model diversity. Model diversity showed that a large portion was neural networks (NN) (64\%) and model type and architecture influence the characteristics of the resulting ML pipelines. %\textcolor{red}{\st{ML pipelines due as pipeline steps can be different since the choice of model type and architecture has an influence on ML pipeline steps}}. 
From the study, the authors \cite{Doris2021MLPipelines} identified data management-related areas as key for optimizing ML pipelines. %\st{From the study, the authors \cite{Doris2021MLPipelines} identified areas for optimizing the ML pipelines, that were mostly related to data management}.

%Data infrastructure is critical when developing an ML-enabled system because it influences the performance, fairness, robustness, safety, and scalability of the system. Developers of ML-enabled systems are often reported to struggle most with data acquisition and management \cite{makinen2021needs}. The latter includes spending a significant portion of time to analyse raw data and handle data errors, such as differences in data distribution at training and serving (training-serving skew). To ensure high-quality data in ML pipelines, data validation tools, such as TFX Data Validation \cite{Baylor2017} are proposed for detecting data errors. These have focus on the data cleaning phase, and there is a need for extension in both upstream (data creation) and downstream (live data after deployment) \cite{Sambasivan2021}.




%Environment abstractions
%The operationalization of ML solutions often involve moving different assets (data, model, application) between different environments up until deployment to production environment. Typically, ML model is developed in an iterative manner in a local environment (e.g., using Jupyter Notebook) with a sample of offline dataset. For production deployment, ML model must be integrated with data infrastructure in order to use live training data as well as with the serving infrastructure in order to 

%Once, implemented ML model can be moved to staging/test environment before deployment to production. Despite the trend of training ML models on the cloud where there is abundant GPU-backed VMs and containers, cite{Hummer2019IBM} noticed a significant number of AI systems use on-premise servers, dedicated clusters, edge devices or a combination and this heterogeneity introduce a number of challenges. 

% Metadata management
%Tracking metadata of AI artifacts across the lifecycle is important for reproduciability of ML experiments. 


% Monitoring




%