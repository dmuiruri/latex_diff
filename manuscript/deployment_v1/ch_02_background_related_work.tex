\section{Background and related work}
\label{sec: background and related work}

Several empirical studies have reported the practices and challenges of ML/DL model development and deployment in industrial settings. The two main distinct phases of the ML lifecycle ---\textit{training and inference}--- focus on running different experiments offline to build an ML model and querying the trained ML model for prediction, respectively. This study focuses on deploying the final trained ML model/inference code and the inference phase. This section synthesizes deployment and inference practices based on prior empirical studies. Thus, we focus on the engineering practices involved after the ML model has been trained and selected for deployment.

\subsection{Trained ML model deployment and inference serving}
\label{subsec: trained ML model deployment}
Trained ML/DL models can be deployed on cloud, edge or IoT platforms~\cite{Hazelwood-FB, Wu-FB-edge} and serve millions of inference queries per second daily. Efficient management of inference workloads is paramount to operate and optimize the running of ML/DL models in production environment~\cite{Park, Boroumand}. A synthesis of the challenges encountered in deploying ML/DL models across different environments is provided by Chen et al.\cite{Chen}, who analyzed 769 relevant developer posts from Stack Overflow.

% With many trained ML/DL models across the services, companies typically adopt model serving platforms, such as KServe and Deep Learning Inference Service~\cite{soifer-MS}. Using services available on model serving platforms, developers can upload their trained models on the platforms, often in specified formats (e.g., ONNX/NNEF for DNN models) or invoke platform services to facilitate ML/DL model deployment in production. The backend services of the model serving platform take care of the uploaded trained models and hardware resources to provide a timely, low-latency response to inference requests. Inference requests can then be submitted to the model serving services via an API by the application. Thus, from the developers' perspective, the model-serving platform abstracts the complexity of autoscaling, networking, and server configurations during model deployment. 

% Deployment of the ML/DL models on the server/cloud is the most common approach. The ML-enabled system contacts an API endpoint of the ML/DL models hosted on the server/cloud to access the models. The deployment procedure of an ML/DL model on the server/cloud platform often involves bundling model artefacts into a package (e.g., Docker image\footnote{https://www.docker.com/}), which, when deployed, will run in an encapsulated computing environment/container (uber, Christidis). Openja et al.~\cite{openja} studied how Docker is used in deployment by analyzing 406 open-source ML-enabled software projects. Their~\cite{openja} analysis of Docker image characteristics showed that, compared to traditional software, building ML-enabled applications requires more computation due to the large number of files with deeply nested directories in the image layers.

Deployment of the ML/DL models on the server/cloud is the most common approach, where an API endpoint is provided to query for predictions. Alternative methods are also applied, such as embedding the model into other software components, where the model is accessed through function calls. The deployment procedure often involves bundling model artefacts into a package (e.g., Docker\footnote{https://www.docker.com/} image) and then using deployment platforms such as KServe\footnote{https://www.kubeflow.org/docs/external-add-ons/kserve/kserve/} or Deep Learning Inference Service~\cite{soifer2019deep} to configure and manage the underlying infrastructure resources. The study by Openja et al.~\cite{openja} showed that Docker supports the portability of models. Still, these docker images require significant computation resources due to many small files and deeply nested directories. Our previous study~\cite{muiruri2022practices} showed a low adoption and usage of ML serving platforms in small and medium-sized companies.

%ML/DL models can be specifically created and deployed on the edge and Internet of Things (IoT) devices/platforms without relying on the cloud. Typically, constraints related to privacy and connectivity motivate the deployment of ML/DL models on edge devices. However, deploying the ML/DL model at the edge is challenged by the diversity and limitations of the hardware (i.e., compute capabilities) available at the edge, amongst others. Due to performance and memory usage requirements, different ML/DL model size optimization techniques, e.g., quantization and compression, are used. Additionally, specialized edge ML accelerators, such as Google's Edge Tensor Processing Unit and NVIDIA Jetson, are used in a few cases \cite{Wu-FB-edge}. Boroumand et al. \cite{Boroumand} identified several shortcomings of edge accelerators from their study of inference execution of 24 state-of-the-art DL models used in Google mobile applications. The authors' findings suggested that critical components of an edge accelerator (e.g. memory system and data flow) must be co-designed and co-customized based on specific ML/DL model layer characteristics to achieve high utilization and energy efficiency. Wu et al. \cite{Wu-FB-edge} noted that using accelerators on edge is primarily for energy efficiency during execution time, and the speedup is secondary. Three deployment procedures of ML/DL models at the edge can be observed to be in use depending on the application domain and the involved design tradeoffs. The first deployment option involves compiling an application containing ML/DL code to platform-specific object code leading to a larger model size but smaller interpreter. The second deployment option uses operating system vendor-specific API, e.g., iOS CoreML. The last option involves deploying a generic interpreter, e.g., TFLite.

Deploying ML/DL for edge/IoT applications often involves converting and packaging the model and its dependencies into a targeted environment. This procedure can be approached in various ways. One by compiling the ML application to architecture-specific binary, for example, creating a Debian package that can be installed in a Linux device. Secondly, using vendor-specific software development kits (SDKs) such as iOS CoreML~\footnote{https://developer.apple.com/documentation/coreml} or using framework-specific tools, such as TFLite\footnote{https://www.tensorflow.org/lite}. Factors such as hardware heterogeneity, multiple runtimes, and performance profiles are some challenges that manifest in edge and IoT-related deployments~\cite{Wu-FB-edge} and can further influence deployment workflows.

The browser is emerging as another viable ML/DL deployment platform. JavaScript-based frameworks, such as TensorFlow.js and WebDNN, are implemented to support the training and inference of ML/DL models in the browsers~\cite{Ma}. Given the browser's limited resources, trained models require an optimization step to ensure they can run within the constraints. Deploying models to the browser environment is relatively easier compared to other platforms~\cite{Chen}.
% For a web application, privacy and real-time response requirements have brought a recent and new trend of performing ML/DL tasks directly on the client side (i.e., using a browser engine to run ML/DL models)~\cite{Goh}. In addition, in-browser ML/DL models help to minimize cross-platform compatibility issues relating to the differences in the underlying hardware (PC, smartphone, wearable) and software (Android, Windows, iOS) ~\cite{Goh}. Various JavaScript-based frameworks, e.g., TensorFlow.js and WebDNN, are implemented to support the training and running of ML/DL models in the browsers \cite{Ma}. Some of the frameworks support the offloading of computation onto a remote server. In-browser ML/DL model deployment and inference involve loading a pre-trained model by downloading a model file from a remote server and getting model outputs with a given input to the model. Like edge deployment, model optimization techniques, like weight quantization, supported by the frameworks, are used to reduce the model size \cite{Goh, Ma}. An empirical study on the feasibility and usability of in-browser DL frameworks showed the need to pre-load the DL model file because the loading process takes longer than the actual inference job \cite{Ma}.

Monitoring is typically performed to track active ML/DL deployments and guarantee the high and accurate performance of the models after the deployment and during inference serving. The performance of ML systems can suffer from data drifts and other drifts in bias and feature attribution (e.g., changes in the relationship between the input and output variable over time)~\cite{Nigenda}. Different metrics are collected, analysed and interpreted to detect abnormal behaviour, determine their causes and perform corrective measures~\cite{Nigenda}.

\subsection{Related Work}
\label{subsec: related work}
% Intro
%The process of engineering software systems has evolved across several methodologies, an approach such as the waterfall approach preceded agile-based practices that also appeared before the DevOps approach emerged. The DevOps approach aims to integrate the development and operations functions. This approach supports the continuous integration and delivery of software~\cite{leite2019survey}, ensuring bug fixes and new features are available reliably fast to end users. Introducing ML models to the software ecosystem tends to introduce an added level of complexity to the engineering process.  This is mainly due to the added dependency on data, ML algorithms, and models, among other artefacts of the ML lifecycle. Engineering ML-enabled software systems may require a different approach~\cite{ozkaya2020really}. These practices are aimed at ensuring an ML-enabled system can be reliably deployed. Unlike DevOps, which has matured over time, practices to develop ML-enabled systems are still in the early stages of being formed as an established philosophy or standardized process. 

% Subject area: SE4AI, CI/CD for ML
With engineering aspects of ML-enabled systems gaining much attention from researchers recently, most studies have focused on identifying general engineering challenges ~\cite{lwakatare2019taxonomy, paleyes2022challenges, giray2021software, martinez2022software, baier2019challenges} and best practices~\cite{serban}. Our study explores the engineering of ML-enable systems in varying maturity levels but focuses on identifying common practices in deploying trained ML models %patterns 
and inference architectures. Paleyes et al. ~\cite{paleyes2022challenges} identify integration, monitoring, and updating of models as sub-steps of the deployment stage. Baier et al.~\cite{baier2019challenges} also distinguish pre-deployment activities from deployment activities where input data, implementation, and infrastructure-related factors are featured. Shankar et al.~\cite{shankar2022operationalizing} cover deployment as part of a broader operations process and indicate that production environments are characterized by the high velocity of experimentation, proactive validation, and maintenance of multiple versions of models. Kolltveit and Li's study~\cite{kolltveit2022operationalizing} focuses on operational activities after model training and evaluation. They outline key aspects of operationalizing ML models: packaging and integration, deployment, serving and inference, and monitoring and logging.  Our study takes a similar approach by focusing on activities after a model has been evaluated and read for inference serving. This way, we provide a deeper insight into integrating the inference code into a targeted environment.
%Software patterns entail reusable solutions to common problems within a given context.  % the rationale of design choices across inference architectures.
Furthermore, our work gives explanation and empirical evidence to studies focusing on understanding general software patterns related to the architecture and design of ML-enabled applications, such as those presented in literature review studies~\cite{washizaki, Lo, heiland2023design} and practitioners' experiences and opinions~\cite{lakshmanan2020machine, take}. Washizaki et al.~\cite{washizaki} summarize and do not elaborate on the listed patterns, and Lo et al.~\cite{Lo} detail patterns for ML systems that apply federated learning. Despite differences in extraction and classification of patterns identified from these studies, examples of patterns presented for the model deployment phase include reusing code between the training pipeline and serving pipeline, decoupling the training pipeline from the production pipeline, event-driven ML microservices, and ML versioning~\cite{washizaki}. %The applicability of well-established patterns to ML systems is explored by Take et al. \cite{take}. Despite differences in extraction and classification of patterns identified from these studies, our work focuses on providing empirical evidence and explanation to the patterns observed as commonly applied deployment practices and inference architectures applicable in different ML system contexts.

% Baier et al. also make use of 11 semi-structure interviews
% https://link.springer.com/chapter/10.1007/978-3-030-64148-1_12
% https://ieeexplore.ieee.org/abstract/document/10081336

% The context of these two papers
% https://arxiv.org/pdf/2209.09125.pdf (Operationalizing Machine Learning: An Interview Study)
%shizaki ete% https://dl.acm.org/doi/pdf/10.1145/3526073.3527584 Operationalizing Machine Learning Models - A Systematic