%This section presents empirical studies on development, deployment, and maintenance of ML-enabled systems. The focus is on works that describe the characteristics of industrial ML workflows and pipelines for ML systems.
%\red{should we add a section intro here? In other sections there is something, but here not?}

\subsection{Software engineering for machine learning}
\DIFdelbegin \DIFdel{Consideration and adaptation }\DIFdelend \DIFaddbegin \DIFadd{Adaptation }\DIFaddend of well-established software engineering (SE) methods and approaches in ML systems have been reported to be crucial \cite{Amershi2019}. This perspective \DIFdelbegin \DIFdel{shifts the focus from just ML algorithms to also include other }\DIFdelend \DIFaddbegin \DIFadd{emphasizes }\DIFaddend important aspects of ML model development and operations in production, such as data management and serving \DIFdelbegin \DIFdel{infrastructures \mbox{%DIFAUXCMD
\cite{Sculley2015}}\hskip0pt%DIFAUXCMD
. Evidence of the integration between SE approaches and ML workflow is in MLOps (machine learning operations), a term used to show the extension of DevOps philosophy of increased agility and automation to the ML workflows \mbox{%DIFAUXCMD
\cite{Zhou2020MLOps}}\hskip0pt%DIFAUXCMD
. In support of the latter, different tools are used to provide automation in ML workflows. 
 %DIF < However, improved integration in the other areas is needed, particularly software testing because either the current approaches do not suffice for ML component \cite{Murphy2007testing, Braiek2020} or have low adoption rates \cite{Serban2020Practices}.
 }\DIFdelend \DIFaddbegin \DIFadd{infrastructure \mbox{%DIFAUXCMD
\cite{Sculley2015}}\hskip0pt%DIFAUXCMD
. Earlier studies observed that companies with fewer years of experience in deploying to production ML components adopt less of the identified SE best practices in ML \mbox{%DIFAUXCMD
\cite{Serban2020Practices}}\hskip0pt%DIFAUXCMD
. In addition, companies are also reported to face different SE challenges at different evolution stages of deploying ML components in software-intensive systems (experimentation \& prototyping, non-critical deployment, critical deployment, cascading deployment, and autonomous ML components) \mbox{%DIFAUXCMD
\cite{Lwakatare2019}}\hskip0pt%DIFAUXCMD
.
%DIF > A taxonomy is proposed and used to map the SE challenges at each evolution stage (experimentation & prototyping, non-critical deployment, critical deployment, cascading deployment, and autonomous ML components). }
}\DIFaddend 

\DIFdelbegin \DIFdel{Best SE practices in ML are identified and their adoption in the industry is surveyed in \mbox{%DIFAUXCMD
\cite{Serban2020Practices}}\hskip0pt%DIFAUXCMD
.
The identified 29 }\DIFdelend %DIF > Best SE practices in ML have been identified and their adoption in the industry surveyed %\st{in}
%DIF > \cite{Serban2020Practices}. 
\DIFaddbegin 

\DIFadd{The identified best }\DIFaddend SE practices in ML \DIFdelbegin \DIFdel{are classified into six categories: (1) }\DIFdelend \DIFaddbegin \DIFadd{include those pertaining to }\DIFaddend data (e.g., employing sanity checks for all external data sources), \DIFdelbegin \DIFdel{(2) }\DIFdelend training (e.g., use versioning for data, model, configurations and training scripts), \DIFdelbegin \DIFdel{(3) }\DIFdelend coding (e.g., using continuous integration\DIFdelbegin \DIFdel{), (4) }\DIFdelend \DIFaddbegin \DIFadd{, }\DIFaddend deployment (e.g., enabling shadow deployment), \DIFdelbegin \DIFdel{(5) }\DIFdelend team (e.g., collaborating with multidisciplinary team members), and \DIFdelbegin \DIFdel{(6) }\DIFdelend governance (enforcing fairness and privacy) \cite{Serban2020Practices}. According to the authors \cite{Serban2020Practices}, the least adopted practices -- related to feature management, writing tests, shadow deployment and automated hyper-parameter optimization -- require effort, knowledge and tool support. 
\DIFdelbegin \DIFdel{This interview study provides some validation and in-depth interpretation to the survey findings related to the adoption of practices  \mbox{%DIFAUXCMD
\cite{Serban2020Practices}}\hskip0pt%DIFAUXCMD
.  
}\DIFdelend 

\DIFdelbegin \subsection{\DIFdel{ML workflow and pipeline}}
%DIFAUXCMD
\addtocounter{subsection}{-1}%DIFAUXCMD
\DIFdelend %DIF > This interview study provides some validation and in-depth interpretation to the survey findings related to the adoption of \textcolor{green}{these} practices \cite{Serban2020Practices}.  

\DIFaddbegin \subsection{\DIFadd{ML workflow and pipelines}}

\DIFaddend ML workflows describe different tasks \DIFdelbegin \DIFdel{that }\DIFdelend \DIFaddbegin \DIFadd{which }\DIFaddend are performed in order to develop, deploy and operate ML models in production \cite{Amershi2019}. ML pipelines are used to express \DIFdelbegin \DIFdel{the }\DIFdelend complex input/output relationship between 
\DIFdelbegin \DIFdel{the }\DIFdelend different tasks/operators of an automated ML workflow \cite{Doris2021MLPipelines}. Generally, ML pipelines plug together several tools \DIFdelbegin \DIFdel{when automating the ML workflow }\DIFdelend \DIFaddbegin \DIFadd{to automate ML workflows }\DIFaddend \cite{Hummer2019IBM}.

\DIFdelbegin \DIFdel{Typical lifecycle phases of ML workflow include }\DIFdelend \DIFaddbegin \DIFadd{A typical ML workflow life-cycle includes }\DIFaddend model requirements, data collection, data cleaning, data labelling, feature engineering, model training, model evaluation, model deployment and model monitoring \cite{Amershi2019}. Studies show that end-to-end automation of ML \DIFdelbegin \DIFdel{workflow }\DIFdelend \DIFaddbegin \DIFadd{workflows }\DIFaddend improves both the development time and rate of deploying ML models \cite{Hummer2019IBM,Doris2021MLPipelines}. Furthermore, \DIFdelbegin \DIFdel{it }\DIFdelend \DIFaddbegin \DIFadd{this }\DIFaddend allows organizations to \DIFdelbegin \DIFdel{(1) automate the }\DIFdelend \DIFaddbegin \DIFadd{automate }\DIFaddend orchestration of workflows steps, \DIFdelbegin \DIFdel{(2) }\DIFdelend track and reproduce the \DIFdelbegin \DIFdel{different outputs of }\DIFdelend \DIFaddbegin \DIFadd{outputs of a }\DIFaddend ML workflow, and \DIFdelbegin \DIFdel{(3) }\DIFdelend reuse common steps of \DIFdelbegin \DIFdel{ML }\DIFdelend \DIFaddbegin \DIFadd{the }\DIFaddend workflow across multiple \DIFdelbegin \DIFdel{ML-enabled }\DIFdelend \DIFaddbegin \DIFadd{ML }\DIFaddend systems \cite{Baylor2017, Hummer2019IBM}. %In addition to ML workflow components, MLOps tools provide utilities to manage pipeline execution and schedule training jobs.

Few studies report in detail the characteristics of ML pipelines \DIFdelbegin \DIFdel{, }\DIFdelend in terms of their components\DIFaddbegin \DIFadd{, }\DIFaddend and architectures \cite{Hummer2019IBM,Doris2021MLPipelines}. Different from our qualitative analysis, Xin et al \cite{Doris2021MLPipelines} quantitatively analysed over 3000 ML pipelines at Google and presented their high-level characteristic in terms of pipeline lifespan, complexity\DIFaddbegin \DIFadd{, }\DIFaddend and resource consumption. For the complexity of ML pipelines, the authors analyzed typical input data shape, feature transformation and model diversity. Model diversity showed that a large portion \DIFdelbegin \DIFdel{used }\DIFdelend \DIFaddbegin \DIFadd{was }\DIFaddend neural networks (NN) (64\%) \DIFdelbegin \DIFdel{. The latter is informs the characteristic of ML pipeline since the choice of }\DIFdelend \DIFaddbegin \DIFadd{and }\DIFaddend model type and architecture \DIFdelbegin \DIFdel{has an influence on ML pipeline steps. From the analysis}\DIFdelend \DIFaddbegin \DIFadd{influence the characteristics of the resulting ML pipelines. %DIF > \textcolor{red}{\st{ML pipelines due as pipeline steps can be different since the choice of model type and architecture has an influence on ML pipeline steps}}. 
From the study}\DIFaddend , the authors \cite{Doris2021MLPipelines} identified \DIFdelbegin \DIFdel{areas for optimizing the ML pipelines, that were mostly related to data management. }\DIFdelend \DIFaddbegin \DIFadd{data management-related areas as key for optimizing ML pipelines. %DIF > \st{From the study, the authors \cite{Doris2021MLPipelines} identified areas for optimizing the ML pipelines, that were mostly related to data management}.
}\DIFaddend 

%Data infrastructure is critical when developing an ML-enabled system because it influences the performance, fairness, robustness, safety, and scalability of the system. Developers of ML-enabled systems are often reported to struggle most with data acquisition and management \cite{makinen2021needs}. The latter includes spending a significant portion of time to analyse raw data and handle data errors, such as differences in data distribution at training and serving (training-serving skew). To ensure high-quality data in ML pipelines, data validation tools, such as TFX Data Validation \cite{Baylor2017} are proposed for detecting data errors. These have focus on the data cleaning phase, and there is a need for extension in both upstream (data creation) and downstream (live data after deployment) \cite{Sambasivan2021}.




%Environment abstractions
%The operationalization of ML solutions often involve moving different assets (data, model, application) between different environments up until deployment to production environment. Typically, ML model is developed in an iterative manner in a local environment (e.g., using Jupyter Notebook) with a sample of offline dataset. For production deployment, ML model must be integrated with data infrastructure in order to use live training data as well as with the serving infrastructure in order to 

%Once, implemented ML model can be moved to staging/test environment before deployment to production. Despite the trend of training ML models on the cloud where there is abundant GPU-backed VMs and containers, cite{Hummer2019IBM} noticed a significant number of AI systems use on-premise servers, dedicated clusters, edge devices or a combination and this heterogeneity introduce a number of challenges. 

% Metadata management
%Tracking metadata of AI artifacts across the lifecycle is important for reproduciability of ML experiments. 


% Monitoring




%