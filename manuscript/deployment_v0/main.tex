\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{booktabs}
\usepackage{makecell}
\usepackage[most]{tcolorbox}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}
\graphicspath{ {./images/} }


\title{Deployment Patterns of Machine Learning Systems: An empirical view} % An empirical view

\author{\IEEEauthorblockN{Dennis Muiruri, Lucy Ellen Lwakatare, Jukka K. Nurminen}
\IEEEauthorblockA{\textit{Computer Science Department} \\
\textit{University of Helsinki}\\
Helsinki, Finland \\
\left\{dennis.muiruri, lucy.lwakatare,jukka.k.nurminen\right\}@helsinki.fi
}}
\and
%\IEEEauthorblockN{2\textsuperscript{nd} Lucy Ellen Lwakatare}
%\IEEEauthorblockA{\textit{Computer Science Department} \\
%\textit{University of Helsinki}\\
%Helsinki, Finland \\
%lucy.lwakatare@helsinki.fi}
% \and
% \IEEEauthorblockN{3\textsuperscript{rd} Jukka K. Nurminen}
% \IEEEauthorblockA{\textit{Computer Science Department} \\
% \textit{University of Helsinki}\\
% Helsinki, Finland \\
% jukka.k.nurminen@helsinki.fi}
\and
\IEEEauthorblockN{Tommi Mikkonen}
\IEEEauthorblockA{\textit{Department of Computer Science} \\
\textit{University of Jyv채skyl채}\\
Jyv채skyl채, Finland \\
tommi.mikkonen@jyvaskyla.fi}
}}

\maketitle

\begin{abstract}
%Background and introduction
As machine learning-enabled systems continue to gain adoption, the engineering aspect of these systems has gained increased attention as the apparent complexities continue to surface.
% Objective
This study aims to explore multiple deployment workflows of various ML-enabled systems in the production phase and extract common patterns from the distinct workflows. We consider the deployment process to begin once an ML model has been trained, verified, and accepted for integration in production systems.
%Methods
Using interviews and a multi-case study design, we analyzed eight ML-enabled systems.
%Results
We discuss the following patterns: model versioning and storage, quality assurance, monitoring, model packaging, serving patterns, and inference serving.
%Conclusion
Although ML domains and architectures may differ, commonly adopted practices can serve as a foundation for establishing a standardized ML engineering process.

\end{abstract}

\begin{IEEEkeywords}
deployment, machine learning engineering, machine learning operations
\end{IEEEkeywords}

\section{Introduction}
\label{sec: introduction}
\input{ch_01_introduction}

% Background and related work
\input{ch_02_background_related_work}

\section{Methodology}
\label{sec: methodology}
\input{ch_03_methodology}

\section{Deployment Workflows and Inference Architectures}
\label{sec: cases}
% A case description has three aspects, the textual description, a diagram, and a table entry. The text description will focus on outlining the processes in a detailed manner while the diagram presents technical/architectural aspects that are best indicated in an annotated diagram than being described. The table entry provides a high-level summary and serves as a comparison tool across the cases.
This section outlines the activities in the deployment procedure of ML models in each studied case. Figure~\ref{fig:deployment_highlevel_framework} summarizes the studied activities in the deployment procedure. For each case, the descriptions provide an overview of the:
\begin{itemize}
    \item ML system use case (or business context)
    \item Integration activities before inference serving, including quality assurance, model packaging, etc. 
    \item Server runtime configurations and server environment setups
    \item Inference service 
    \item Monitoring activities 
\end{itemize}  

%This section outlines the procedure followed in the case study process and a detailed description of each case. The model deployment workflow starts with a validated model artefact produced from the model experiment phase by the model training and testing phase.
%The studied cases are presented in five distinct sections: i) A description of the business context of the ML system, ii) An examination of pre-integration activities, including quality assurance, model packaging, and any other preparations undertaken before inference serving. iii) An examination of server runtime configurations and server environment setups. iv) An examination of serving inference, and finally, v) an analysis of the monitoring activities in place. A comprehensive illustration of this framework is presented in figure~\ref{fig:deployment_highlevel_framework}.


\subsection*{Case 1}\label{1}
\input{cases/case_1}

\subsection*{Case 2}\label{2}
\input{cases/case_2}

\subsection*{Case 3}\label{3}
\input{cases/case_3}

\input{cases/case_4}
\input{cases/case_5}
\input{cases/case_6}
\input{cases/case_7}
\input{cases/case_8}
\input{tables/summary_of_cases.tex}

\section{Patterns in ML deployment workflows}
\label{sec: patterns}
\input{ch_05_patterns}

% Section: Discussion
\input{ch_06_discussion}

\section{Validity}
\label{sec: validity}
\input{ch_07_validity_conclusion}

\section*{Acknowledgment}

This work was supported in part by local authorities (Business Finland) under grant agreements ITEA-2019-18022-IVVES https://ivves.eu/ ITEA3 program and ITEA-2021-20219-IML4E https://iml4e.org/ of ITEA4 program.

% Section: References
\bibliographystyle{plain} % We choose the "plain" reference style
\bibliography{references}

\end{document}
I am running a few minutes late; my previous meeting is running over.